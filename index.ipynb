{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning and Optimizing Neural Networks - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that we've discussed some regularization, initialization and optimization techniques, its time to synthesize those concepts into a cohesive modelling pipeline.  \n",
    "\n",
    "With this pipeline, yoiu will not only fit an initial model but will also attempt to set various hyperparameters for regularization techniques. Your final model selection will pertain to the test metrics across these models. This will more naturally simulate a problem you might be faced with in practice, and the various modelling decisions you are apt to encounter along the way.  \n",
    "\n",
    "Recall that our end objective is to achieve a balance between overfitting and underfitting. We've discussed the bias variance tradeoff, and the role of regularization in order to reduce overfitting on training data and improving generalization to new cases. Common frameworks for such a procedure include train/validate/test methodology when data is plentiful, and K-folds cross-validation for smaller, more limited datasets. In this lab, you'll perform the latter, as the dataset in question is fairly limited. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Implement a K-folds cross validation modelling pipeline\n",
    "* Apply normalization as a preprocessing technique\n",
    "* Apply regularization techniques to improve your model's generalization\n",
    "* Choose an appropriate optimization strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Your code here; load and preview the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras import initializers\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>application_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>car</td>\n",
       "      <td>GA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1014.530000</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>small_business</td>\n",
       "      <td>IL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3005.666844</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>other</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.0</td>\n",
       "      <td>12231.890000</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>other</td>\n",
       "      <td>OR</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4066.908161</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt_inv        term int_rate  installment grade  \\\n",
       "0     5000.0           4975.0   36 months   10.65%       162.87     B   \n",
       "1     2500.0           2500.0   60 months   15.27%        59.83     C   \n",
       "2     2400.0           2400.0   36 months   15.96%        84.33     C   \n",
       "3    10000.0          10000.0   36 months   13.49%       339.31     C   \n",
       "4     3000.0           3000.0   60 months   12.69%        67.79     B   \n",
       "\n",
       "  emp_length home_ownership  annual_inc verification_status  loan_status  \\\n",
       "0  10+ years           RENT     24000.0            Verified   Fully Paid   \n",
       "1   < 1 year           RENT     30000.0     Source Verified  Charged Off   \n",
       "2  10+ years           RENT     12252.0        Not Verified   Fully Paid   \n",
       "3  10+ years           RENT     49200.0     Source Verified   Fully Paid   \n",
       "4     1 year           RENT     80000.0     Source Verified   Fully Paid   \n",
       "\n",
       "          purpose addr_state  total_acc   total_pymnt application_type  \n",
       "0     credit_card         AZ        9.0   5863.155187       Individual  \n",
       "1             car         GA        4.0   1014.530000       Individual  \n",
       "2  small_business         IL       10.0   3005.666844       Individual  \n",
       "3           other         CA       37.0  12231.890000       Individual  \n",
       "4           other         OR       38.0   4066.908161       Individual  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('loan_final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42538, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42538 entries, 0 to 42537\n",
      "Data columns (total 16 columns):\n",
      "loan_amnt              42535 non-null float64\n",
      "funded_amnt_inv        42535 non-null float64\n",
      "term                   42535 non-null object\n",
      "int_rate               42535 non-null object\n",
      "installment            42535 non-null float64\n",
      "grade                  42535 non-null object\n",
      "emp_length             41423 non-null object\n",
      "home_ownership         42535 non-null object\n",
      "annual_inc             42531 non-null float64\n",
      "verification_status    42535 non-null object\n",
      "loan_status            42535 non-null object\n",
      "purpose                42535 non-null object\n",
      "addr_state             42535 non-null object\n",
      "total_acc              42506 non-null float64\n",
      "total_pymnt            42535 non-null float64\n",
      "application_type       42535 non-null object\n",
      "dtypes: float64(6), object(10)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Problem\n",
    "\n",
    "Set up the problem by defining X and Y. \n",
    "\n",
    "For this problem use the following variables for X:\n",
    "* loan_amnt\n",
    "* home_ownership\n",
    "* funded_amnt_inv\n",
    "* verification_status\n",
    "* emp_length\n",
    "* installment\n",
    "* annual_inc\n",
    "\n",
    "Be sure to use dummy variables for categorical variables and to normalize numerical quanitities. Be sure to also remove any rows with null data.  \n",
    "\n",
    "For Y, we are looking to build a model to predict the total payment received for a loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here; appropriately define X and Y using dummy variables and normalization for preprocessing.\n",
    "df=df.dropna()\n",
    "X=df[['loan_amnt','home_ownership','funded_amnt_inv','verification_status','emp_length','installment','annual_inc']]\n",
    "y=(df['total_pymnt']-np.mean(df['total_pymnt']))/np.std(df['total_pymnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41394 entries, 0 to 42516\n",
      "Data columns (total 7 columns):\n",
      "loan_amnt              41394 non-null float64\n",
      "home_ownership         41394 non-null object\n",
      "funded_amnt_inv        41394 non-null float64\n",
      "verification_status    41394 non-null object\n",
      "emp_length             41394 non-null object\n",
      "installment            41394 non-null float64\n",
      "annual_inc             41394 non-null float64\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\kosta\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\kosta\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\kosta\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\kosta\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_NONE</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>verification_status_Not Verified</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length_10+ years</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.831064</td>\n",
       "      <td>-0.731196</td>\n",
       "      <td>-0.774545</td>\n",
       "      <td>-0.708860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.168176</td>\n",
       "      <td>-1.077707</td>\n",
       "      <td>-1.267125</td>\n",
       "      <td>-0.615909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.181661</td>\n",
       "      <td>-1.091707</td>\n",
       "      <td>-1.150003</td>\n",
       "      <td>-0.890856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.156841</td>\n",
       "      <td>-0.027675</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>-0.318468</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.100754</td>\n",
       "      <td>-1.007705</td>\n",
       "      <td>-1.229072</td>\n",
       "      <td>0.158677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt_inv  installment  annual_inc  \\\n",
       "0  -0.831064        -0.731196    -0.774545   -0.708860   \n",
       "1  -1.168176        -1.077707    -1.267125   -0.615909   \n",
       "2  -1.181661        -1.091707    -1.150003   -0.890856   \n",
       "3  -0.156841        -0.027675     0.068920   -0.318468   \n",
       "4  -1.100754        -1.007705    -1.229072    0.158677   \n",
       "\n",
       "   home_ownership_MORTGAGE  home_ownership_NONE  home_ownership_OTHER  \\\n",
       "0                        0                    0                     0   \n",
       "1                        0                    0                     0   \n",
       "2                        0                    0                     0   \n",
       "3                        0                    0                     0   \n",
       "4                        0                    0                     0   \n",
       "\n",
       "   home_ownership_OWN  home_ownership_RENT  verification_status_Not Verified  \\\n",
       "0                   0                    1                                 0   \n",
       "1                   0                    1                                 0   \n",
       "2                   0                    1                                 1   \n",
       "3                   0                    1                                 0   \n",
       "4                   0                    1                                 0   \n",
       "\n",
       "          ...           emp_length_10+ years  emp_length_2 years  \\\n",
       "0         ...                              1                   0   \n",
       "1         ...                              0                   0   \n",
       "2         ...                              1                   0   \n",
       "3         ...                              1                   0   \n",
       "4         ...                              0                   0   \n",
       "\n",
       "   emp_length_3 years  emp_length_4 years  emp_length_5 years  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   emp_length_6 years  emp_length_7 years  emp_length_8 years  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   emp_length_9 years  emp_length_< 1 year  \n",
       "0                   0                    0  \n",
       "1                   0                    1  \n",
       "2                   0                    0  \n",
       "3                   0                    0  \n",
       "4                   0                    0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "X['loan_amnt']=(X['loan_amnt']-np.mean(X['loan_amnt']))/np.std(X['loan_amnt'])\n",
    "X['funded_amnt_inv']=scaler.fit_transform(np.array(X['funded_amnt_inv']).reshape(-1,1))\n",
    "X['installment']=scaler.fit_transform(np.array(X['installment']).reshape(-1,1))\n",
    "X['annual_inc']=scaler.fit_transform(np.array(X['annual_inc']).reshape(-1,1))\n",
    "X=pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41394, 23)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Hold Out Test Set\n",
    "\n",
    "While we will be using K-fold cross validation to select an optimal model, we still want a final hold out test set that is completely independent of any modelling decisions. As such, pull out a sample of 10% of the total available data. For consistency of results, use random seed 123. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here; generate a hold out test set for final model evaluation. Use random seed 123.\n",
    "# data_clean = pd.concat([X, y], axis=1)\n",
    "# np.random.seed(123)\n",
    "# train, test = train_test_split(data_clean, test_size=0.1)\n",
    "\n",
    "# X_test = test.iloc[:,0:23]\n",
    "# y_test = test.iloc[:,23]\n",
    "# X_train = train.iloc[:,0:23]\n",
    "# y_train = train.iloc[:,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_NONE</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>verification_status_Not Verified</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length_10+ years</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24882</th>\n",
       "      <td>0.112849</td>\n",
       "      <td>0.021326</td>\n",
       "      <td>-0.286460</td>\n",
       "      <td>0.189661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>-0.669251</td>\n",
       "      <td>-0.559691</td>\n",
       "      <td>-0.587677</td>\n",
       "      <td>-0.151157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32465</th>\n",
       "      <td>0.841010</td>\n",
       "      <td>1.008356</td>\n",
       "      <td>1.374322</td>\n",
       "      <td>0.468512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34510</th>\n",
       "      <td>-0.831064</td>\n",
       "      <td>-0.727696</td>\n",
       "      <td>-0.806909</td>\n",
       "      <td>-0.306075</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>0.921917</td>\n",
       "      <td>1.092359</td>\n",
       "      <td>1.162835</td>\n",
       "      <td>0.158677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_amnt  funded_amnt_inv  installment  annual_inc  \\\n",
       "24882   0.112849         0.021326    -0.286460    0.189661   \n",
       "5723   -0.669251        -0.559691    -0.587677   -0.151157   \n",
       "32465   0.841010         1.008356     1.374322    0.468512   \n",
       "34510  -0.831064        -0.727696    -0.806909   -0.306075   \n",
       "9396    0.921917         1.092359     1.162835    0.158677   \n",
       "\n",
       "       home_ownership_MORTGAGE  home_ownership_NONE  home_ownership_OTHER  \\\n",
       "24882                        1                    0                     0   \n",
       "5723                         0                    0                     0   \n",
       "32465                        1                    0                     0   \n",
       "34510                        1                    0                     0   \n",
       "9396                         0                    0                     0   \n",
       "\n",
       "       home_ownership_OWN  home_ownership_RENT  \\\n",
       "24882                   0                    0   \n",
       "5723                    0                    1   \n",
       "32465                   0                    0   \n",
       "34510                   0                    0   \n",
       "9396                    0                    1   \n",
       "\n",
       "       verification_status_Not Verified         ...           \\\n",
       "24882                                 0         ...            \n",
       "5723                                  1         ...            \n",
       "32465                                 1         ...            \n",
       "34510                                 1         ...            \n",
       "9396                                  0         ...            \n",
       "\n",
       "       emp_length_10+ years  emp_length_2 years  emp_length_3 years  \\\n",
       "24882                     1                   0                   0   \n",
       "5723                      0                   0                   0   \n",
       "32465                     0                   0                   0   \n",
       "34510                     0                   0                   1   \n",
       "9396                      0                   0                   0   \n",
       "\n",
       "       emp_length_4 years  emp_length_5 years  emp_length_6 years  \\\n",
       "24882                   0                   0                   0   \n",
       "5723                    0                   0                   0   \n",
       "32465                   0                   0                   0   \n",
       "34510                   0                   0                   0   \n",
       "9396                    0                   1                   0   \n",
       "\n",
       "       emp_length_7 years  emp_length_8 years  emp_length_9 years  \\\n",
       "24882                   0                   0                   0   \n",
       "5723                    0                   0                   0   \n",
       "32465                   0                   1                   0   \n",
       "34510                   0                   0                   0   \n",
       "9396                    0                   0                   0   \n",
       "\n",
       "       emp_length_< 1 year  \n",
       "24882                    0  \n",
       "5723                     0  \n",
       "32465                    0  \n",
       "34510                    0  \n",
       "9396                     0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a K-fold Cross Validation Methodology\n",
    "\n",
    "Now that your have a complete holdout test set, write a function that takes in the remaining data and performs k-folds cross validation given a model object. Be sure your function returns performance metrics regarding the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-56-c61c447b95a0>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-56-c61c447b95a0>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def k_folds(features_train, labels_train, model_obj, k=10, n_epochs=100)\u001b[0m\n\u001b[1;37m                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Your code here; define a function to evaluate a model object using K folds cross validation.\n",
    "\n",
    "def k_folds(features_train, labels_train, model_obj, k=10, n_epochs=100):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from solutions page\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def k_folds(features_train, labels_train, model_obj, k=10, n_epochs=100):\n",
    "    colors = sns.color_palette(\"Set2\")\n",
    "\n",
    "    validation_scores = [] \n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12,8))\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(features_train)):\n",
    "        \"Currently graph imaging assumes 10 folds and is hardcoded to 5x2 layout.\"\n",
    "        row = i//5\n",
    "        col = i%5\n",
    "        X_train, X_val = features_train.iloc[train_index], features_train.iloc[test_index]\n",
    "        y_train, y_val = labels_train.iloc[train_index], labels_train.iloc[test_index]\n",
    "        \n",
    "        model = model_obj\n",
    "        hist = model.fit(X_train.values, y_train.values, batch_size=32,\n",
    "                         epochs=n_epochs, verbose=0, validation_data = (X_val, y_val))\n",
    "        #Note: verboxe=0 turns off printouts regarding training for each epoch.\n",
    "        #Potential simpler methodology\n",
    "        validation_score = model.evaluate(X_val, y_val)\n",
    "        validation_scores.append(validation_score)\n",
    "        ax = axes[row, col]\n",
    "        k = 'val_loss'\n",
    "        d = hist.history[k]\n",
    "        ax.plot(d, label=k, color=colors[0])\n",
    "\n",
    "        k = 'loss'\n",
    "        d = hist.history[k]\n",
    "        ax.plot(d, label=k, color=colors[1])\n",
    "        ax.set_title('Fold {} Validation'.format(i+1))\n",
    "    #Final Graph Formatting\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=None)\n",
    "    plt.legend(bbox_to_anchor=(1,1))\n",
    "    \n",
    "    #General Overview\n",
    "    validation_score = np.average(validation_scores)\n",
    "    print('Mean Validation Score:', validation_score)\n",
    "    print('Standard Deviation of Validation Scores:', np.std(validation_scores))\n",
    "    return validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Baseline Model\n",
    "\n",
    "Here, it is also important to define your evaluation metric that you will look to optimize while tuning the model.   \n",
    "\n",
    "In general, model training to optimize this metric may consist of using a validation and test set if data is plentiful, or k-folds cross-validation if data is limited. We set up a k-folds cross-validation for this task since the dataset is not overly large.  \n",
    "\n",
    "Build an initial sequential model with 2 hidden relu layers. The first should have 7 hidden units, and the second 10 hidden units. Finally, add a third layer with a linear activation function to output our predictions for the total loan payment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; define and compile an initial model as described\n",
    "model=Sequential()\n",
    "model.add(layers.Dense(7,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer= \"sgd\" ,loss='mse',metrics=['mse'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.2387 - mean_squared_error: 0.2387\n",
      "Epoch 2/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.2040 - mean_squared_error: 0.2040\n",
      "Epoch 3/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.2010 - mean_squared_error: 0.2010\n",
      "Epoch 4/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1992 - mean_squared_error: 0.1992\n",
      "Epoch 5/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1984 - mean_squared_error: 0.1984\n",
      "Epoch 6/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1969 - mean_squared_error: 0.1969\n",
      "Epoch 7/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1963 - mean_squared_error: 0.1963\n",
      "Epoch 8/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1954 - mean_squared_error: 0.1954\n",
      "Epoch 9/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1954 - mean_squared_error: 0.1954\n",
      "Epoch 10/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1946 - mean_squared_error: 0.1946\n",
      "Epoch 11/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1941 - mean_squared_error: 0.1941\n",
      "Epoch 12/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1932 - mean_squared_error: 0.1932\n",
      "Epoch 13/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1926 - mean_squared_error: 0.1926\n",
      "Epoch 14/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1922 - mean_squared_error: 0.1922\n",
      "Epoch 15/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1919 - mean_squared_error: 0.1919\n",
      "Epoch 16/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1914 - mean_squared_error: 0.1914\n",
      "Epoch 17/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1917 - mean_squared_error: 0.1917\n",
      "Epoch 18/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1915 - mean_squared_error: 0.1915\n",
      "Epoch 19/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1911 - mean_squared_error: 0.1911\n",
      "Epoch 20/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1909 - mean_squared_error: 0.1909\n",
      "Epoch 21/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1913 - mean_squared_error: 0.1913\n",
      "Epoch 22/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1906 - mean_squared_error: 0.1906\n",
      "Epoch 23/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1903 - mean_squared_error: 0.1903\n",
      "Epoch 24/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1897 - mean_squared_error: 0.1897\n",
      "Epoch 25/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1902 - mean_squared_error: 0.1902\n",
      "Epoch 26/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1899 - mean_squared_error: 0.1899\n",
      "Epoch 27/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1901 - mean_squared_error: 0.1901\n",
      "Epoch 28/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1900 - mean_squared_error: 0.1900\n",
      "Epoch 29/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1902 - mean_squared_error: 0.1902\n",
      "Epoch 30/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1896 - mean_squared_error: 0.1896\n",
      "Epoch 31/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1898 - mean_squared_error: 0.1898\n",
      "Epoch 32/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1899 - mean_squared_error: 0.1899\n",
      "Epoch 33/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1896 - mean_squared_error: 0.1896 0s - loss: 0.185\n",
      "Epoch 34/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1897 - mean_squared_error: 0.1897\n",
      "Epoch 35/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1891 - mean_squared_error: 0.1891\n",
      "Epoch 36/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1893 - mean_squared_error: 0.1893\n",
      "Epoch 37/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1896 - mean_squared_error: 0.1896\n",
      "Epoch 38/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1889 - mean_squared_error: 0.1889\n",
      "Epoch 39/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1894 - mean_squared_error: 0.1894\n",
      "Epoch 40/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1892 - mean_squared_error: 0.1892\n",
      "Epoch 41/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1893 - mean_squared_error: 0.1893\n",
      "Epoch 42/100\n",
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1893 - mean_squared_error: 0.1893\n",
      "Epoch 43/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1891 - mean_squared_error: 0.1891\n",
      "Epoch 44/100\n",
      "37254/37254 [==============================] - 2s 50us/step - loss: 0.1893 - mean_squared_error: 0.1893\n",
      "Epoch 45/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1891 - mean_squared_error: 0.1891\n",
      "Epoch 46/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1888 - mean_squared_error: 0.1888\n",
      "Epoch 47/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1891 - mean_squared_error: 0.1891\n",
      "Epoch 48/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1891 - mean_squared_error: 0.1891\n",
      "Epoch 49/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1888 - mean_squared_error: 0.1888\n",
      "Epoch 50/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1893 - mean_squared_error: 0.1893\n",
      "Epoch 51/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1889 - mean_squared_error: 0.1889\n",
      "Epoch 52/100\n",
      "37254/37254 [==============================] - 2s 50us/step - loss: 0.1892 - mean_squared_error: 0.1892\n",
      "Epoch 53/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1888 - mean_squared_error: 0.1888\n",
      "Epoch 54/100\n",
      "37254/37254 [==============================] - 2s 51us/step - loss: 0.1889 - mean_squared_error: 0.1889\n",
      "Epoch 55/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1887 - mean_squared_error: 0.1887\n",
      "Epoch 56/100\n",
      "37254/37254 [==============================] - 2s 51us/step - loss: 0.1890 - mean_squared_error: 0.1890\n",
      "Epoch 57/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1886 - mean_squared_error: 0.1886\n",
      "Epoch 58/100\n",
      "37254/37254 [==============================] - 2s 55us/step - loss: 0.1886 - mean_squared_error: 0.1886\n",
      "Epoch 59/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1886 - mean_squared_error: 0.1886\n",
      "Epoch 60/100\n",
      "37254/37254 [==============================] - 2s 52us/step - loss: 0.1886 - mean_squared_error: 0.1886\n",
      "Epoch 61/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1889 - mean_squared_error: 0.1889\n",
      "Epoch 62/100\n",
      "37254/37254 [==============================] - 2s 52us/step - loss: 0.1885 - mean_squared_error: 0.1885\n",
      "Epoch 63/100\n",
      "37254/37254 [==============================] - 2s 53us/step - loss: 0.1884 - mean_squared_error: 0.1884 0s - loss: 0.187\n",
      "Epoch 64/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1888 - mean_squared_error: 0.1888\n",
      "Epoch 65/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1883 - mean_squared_error: 0.1883\n",
      "Epoch 66/100\n",
      "37254/37254 [==============================] - 2s 50us/step - loss: 0.1884 - mean_squared_error: 0.1884\n",
      "Epoch 67/100\n",
      "37254/37254 [==============================] - 2s 50us/step - loss: 0.1887 - mean_squared_error: 0.1887\n",
      "Epoch 68/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1888 - mean_squared_error: 0.1888\n",
      "Epoch 69/100\n",
      "37254/37254 [==============================] - 2s 48us/step - loss: 0.1885 - mean_squared_error: 0.1885\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37254/37254 [==============================] - 2s 46us/step - loss: 0.1883 - mean_squared_error: 0.1883\n",
      "Epoch 71/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1884 - mean_squared_error: 0.1884\n",
      "Epoch 72/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1881 - mean_squared_error: 0.1881\n",
      "Epoch 73/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1884 - mean_squared_error: 0.1884\n",
      "Epoch 74/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1884 - mean_squared_error: 0.1884\n",
      "Epoch 75/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1883 - mean_squared_error: 0.1883\n",
      "Epoch 76/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1880 - mean_squared_error: 0.1880\n",
      "Epoch 77/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1882 - mean_squared_error: 0.1882\n",
      "Epoch 78/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1885 - mean_squared_error: 0.1885\n",
      "Epoch 79/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1882 - mean_squared_error: 0.1882\n",
      "Epoch 80/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1879 - mean_squared_error: 0.1879\n",
      "Epoch 81/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1880 - mean_squared_error: 0.1880\n",
      "Epoch 82/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1882 - mean_squared_error: 0.1882\n",
      "Epoch 83/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1879 - mean_squared_error: 0.1879\n",
      "Epoch 84/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1882 - mean_squared_error: 0.1882\n",
      "Epoch 85/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1877 - mean_squared_error: 0.1877\n",
      "Epoch 86/100\n",
      "37254/37254 [==============================] - 2s 42us/step - loss: 0.1880 - mean_squared_error: 0.1880\n",
      "Epoch 87/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1876 - mean_squared_error: 0.1876\n",
      "Epoch 88/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1877 - mean_squared_error: 0.1877\n",
      "Epoch 89/100\n",
      "37254/37254 [==============================] - 2s 45us/step - loss: 0.1886 - mean_squared_error: 0.1886\n",
      "Epoch 90/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1878 - mean_squared_error: 0.1878\n",
      "Epoch 91/100\n",
      "37254/37254 [==============================] - 2s 47us/step - loss: 0.1880 - mean_squared_error: 0.1880\n",
      "Epoch 92/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1878 - mean_squared_error: 0.1878\n",
      "Epoch 93/100\n",
      "37254/37254 [==============================] - 2s 49us/step - loss: 0.1876 - mean_squared_error: 0.1876\n",
      "Epoch 94/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1874 - mean_squared_error: 0.1874\n",
      "Epoch 95/100\n",
      "37254/37254 [==============================] - 2s 43us/step - loss: 0.1885 - mean_squared_error: 0.1885\n",
      "Epoch 96/100\n",
      "37254/37254 [==============================] - 2s 44us/step - loss: 0.1877 - mean_squared_error: 0.1877\n",
      "Epoch 97/100\n",
      "37254/37254 [==============================] - 2s 66us/step - loss: 0.1874 - mean_squared_error: 0.1874\n",
      "Epoch 98/100\n",
      "37254/37254 [==============================] - 2s 61us/step - loss: 0.1875 - mean_squared_error: 0.1875\n",
      "Epoch 99/100\n",
      "37254/37254 [==============================] - 2s 50us/step - loss: 0.1874 - mean_squared_error: 0.1874\n",
      "Epoch 100/100\n",
      "37254/37254 [==============================] - 2s 50us/step - loss: 0.1875 - mean_squared_error: 0.1875\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train.values,y_train.values,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e74b630>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Baseline Model with K-Folds Cross Validation\n",
    "\n",
    "Use your k-folds function to evaluate the baseline model.  \n",
    "\n",
    "Note: This code block is likely to take 10-20 minutes to run depending on the specs on your computer.\n",
    "Because of time dependencies, it can be interesting to begin timing these operations for future reference.\n",
    "\n",
    "Here's a simple little recipe to achieve this:\n",
    "```\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "later = datetime.datetime.now()\n",
    "elapsed = later - now\n",
    "print('Time Elapsed:', elapsed)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-56cbda691973>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Your code here; use your k-folds function to evaluate the baseline model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mk_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_obj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-65-6be6da5ff0c2>\u001b[0m in \u001b[0;36mk_folds\u001b[1;34m(features_train, labels_train, model_obj, k, n_epochs)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Your code here; use your k-folds function to evaluate the baseline model.\n",
    "k_folds(features_train=X_train.values,labels_train=y_train.values,model_obj=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intentionally Overfitting a Model\n",
    "\n",
    "Now that you've developed a baseline model, its time to intentionally overfit a model. To overfit a model, you can:\n",
    "* Add layers\n",
    "* Make the layers bigger\n",
    "* Increase the number of training epochs\n",
    "\n",
    "Again, be careful here. Think about the limitations of your resources, both in terms of your computers specs and how much time and patience you have to let the process run. Also keep in mind that you will then be regularizing these overfit models, meaning another round of experiments and more time and resources.  \n",
    "\n",
    "For example, here are some timing notes on potential experiments run on a Macbook Pro 3.1 GHz Intel Core i5 with 16gb of RAM:\n",
    "\n",
    "* Using our 10 fold cross validation methodology, a 5-layer neural network with 10 units per hidden layer and 100 epochs took approximately 15 minutes to train and validate  \n",
    "\n",
    "* Using our 10 fold cross validation methodology, a 5-layer neural network with 25 units per hidden layer and 100 epochs took approximately 25 minutes to train and validate  \n",
    "\n",
    "* Using our 10 fold cross validation methodology, a 5-layer neural network with 10 units per hidden layer and 250 epochs took approximately 45 minutes to train and validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some methods to overfit your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some methods to overfit your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some methods to overfit your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing the Model to Achieve Balance  \n",
    "\n",
    "Now that you have a powerful model (albeit an overfit one), we can now increase the generalization of the model by using some of the regularization techniques we discussed. Some options you have to try include:  \n",
    "* Adding dropout\n",
    "* Adding L1/L2 regularization\n",
    "* Altering the layer architecture (add or remove layers similar to above)  \n",
    "\n",
    "This process will be constrained by time and resources. Be sure to test at least 2 different methodologies, such as dropout and L2 regularization. If you have the time, feel free to continue experimenting.\n",
    "\n",
    "Notes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some regularization or other methods to tune your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some regularization or other methods to tune your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some regularization or other methods to tune your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; try some regularization or other methods to tune your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "\n",
    "Now that you have selected a network architecture, tested various regularization procedures and tuned hyperparameters via a validation methodology, it is time to evaluate your finalized model once and for all. Fit the model using all of the training and validation data using the architecture and hyperparameters that were most effective in your expirements above. Afterwards, measure the overall performance on the hold-out test data which has been left untouched (and hasn't leaked any data into the modelling process)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; final model training on entire training set followed by evaluation on hold-out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n",
    "\n",
    "https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network\n",
    "https://www.springboard.com/blog/free-public-data-sets-data-science-project/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we investigated some data from *The Lending Club* in a complete data science pipeline regarding neural networks. We began with reserving a hold-out set for testing which never was touched during the modeling phase. From there, we implemented a k-fold cross validation methodology in order to assess an initial baseline model and various regularization methods. From here, we'll begin to investigate other neural network architectures such as CNNs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
